{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Disclaimer\n",
        "This code is taken from this [notebook](https://colab.research.google.com/drive/1XSnIhSIsw3LMc6mkXlw66sMc7ZwFAJKT?usp=sharing). I only take the important part of Decision Tree Learning and adding the code to save the models.\n",
        "\n",
        "---\n",
        "\n",
        "##Continue the Learning!\n",
        "\n",
        "Now that you have one classification technique down, let's try another, **Decision Trees**. We will also be discuss a way to analyze accuracy called a **Confusion Matrix**.\n",
        "\n",
        "\n",
        "##Decision Trees: Importing and Cleaning up the Data\n",
        "We already loaded the data in the beginning. Let's load it again, just in case you are starting to run the code from here."
      ],
      "metadata": {
        "id": "0CCFln6m6Prc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzXh8qGb5p3k"
      },
      "outputs": [],
      "source": [
        "#Import required libraries\n",
        "import pandas as pd #loading data in table form\n",
        "import numpy as np # linear algebra\n",
        "from sklearn.tree import DecisionTreeClassifier #Creating the Decision Tree\n",
        "from sklearn import tree#Visualizing the Decision Tree\n",
        "import graphviz #Visualizing the Decision Tree\n",
        "from sklearn.metrics import confusion_matrix #Confusion Matrix\n",
        "import matplotlib.pyplot as plt #visualization\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load the dataset, which contains the examples and their labels\n",
        "iris_dataset = load_iris()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Tree: Splitting up the training and test sets\n",
        "\n",
        "Remember that in classification, which is a type of supervised machine learning, we must use a training set to teach our model how to correctly classify future examples. We also use a test set to test how good our model is.\n",
        "\n",
        "The first step that we'll do is break up the Iris dataset into training set and test set:"
      ],
      "metadata": {
        "id": "PaWFWrgP6vB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Break the dataset up into the examples (X) and their labels (y)\n",
        "X, y = iris_dataset.data, iris_dataset.target\n",
        "\n",
        "# Split up the X and y datasets into train and test sets\n",
        "# 25% of the dataset will be used for the test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=31)"
      ],
      "metadata": {
        "id": "8ixcuTas527Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our training set contains all of the correct targets (classes) for our flower examples, along with the four features of each flower. We'll need all of this information to teach our classifier how to predict a class given a new set of four features.\n",
        "\n",
        "**Note: Because the data points are split randomly into train and test, each run might not be the same**\n",
        "\n",
        "## Decision Tree: Training our Classifier\n",
        "\n",
        "As Decision Trees are a well-known classifier. There is already a library with a function to make one. You can always create it from scratch, but sometimes using the library function is less tedius. When you need to customize more advanced aspects of the classifier, it makes sense to start from scratch, unlike here."
      ],
      "metadata": {
        "id": "DX5R-_9v6xSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sklearn classifiers built in\n",
        "# We're going to import the decision tree classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize the classifier with a max_depth of 5\n",
        "classifier = DecisionTreeClassifier(max_depth=5)\n",
        "\n",
        "# Fit the classifier to the training set\n",
        "classifier = classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "WMxvKnVt56yD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Decision Tree: Testing\n",
        "We've trained our decision tree and visualized it, but we have not yet tested it to see how well it does. This is where the test set comes in -- the test set is a set of correctly labelled examples that we have withheld from the decision tree, so we can test to see if the predictions made by the decision tree match the correct labels.\n",
        "\n",
        "With `sklearn`, it's really easy to generate our predicted labels for the test set:\n"
      ],
      "metadata": {
        "id": "yViu4cnY655r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of predicted classes for each of the examples in the test set\n",
        "y_predict = classifier.predict(X_test)"
      ],
      "metadata": {
        "id": "0F3D0KtY64y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to find the accuracy of our classifier on the test set, we use the function `score()`, which takes two parameters: (1) the data of the test set, and (2) the correct labels of the test set.\n",
        "\n",
        "It will automatically compare our predicted label with the correct label to compute the accuracy."
      ],
      "metadata": {
        "id": "Hhd9jOJk7AMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = classifier.score(X_test, y_test)\n",
        "print(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcRjFDjQ690B",
        "outputId": "0d65dd01-f3ae-4baf-a0ca-2aa54c0c1438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9473684210526315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Save Model\n",
        "Save model using joblib"
      ],
      "metadata": {
        "id": "ufyPxNgJ7EoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "filename = 'model.sav'\n",
        "joblib.dump(classifier, filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFcrYGuk7Cxd",
        "outputId": "43a9c932-998f-4c9e-8168-ea09b8e2d1da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model.sav']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Model\n",
        "To make sure that the saved models are work as expected"
      ],
      "metadata": {
        "id": "AzYbX_nA7nQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model from disk\n",
        "loaded_model = joblib.load(filename)\n",
        "\n",
        "result = loaded_model.score(X_test, y_test)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQktIs9-7e4w",
        "outputId": "ec2aa4be-868f-4948-f1c6-57be624cec14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9473684210526315\n"
          ]
        }
      ]
    }
  ]
}